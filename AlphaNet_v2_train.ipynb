{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69367752",
   "metadata": {},
   "source": [
    "# AlphaNet_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c629b09",
   "metadata": {},
   "source": [
    "1. 扩充了6个比率类特征，“数据图片”维度变为15*30\n",
    "2. 将池化层和全连接层替换为LSTM层，从而更好地学习特征的时序信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b349dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from audtorch.metrics.functional import pearsonr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ff734",
   "metadata": {},
   "source": [
    "# 自定义卷积核(特征提取)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee78149",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列和Y值构成的时序数列的相关系数\n",
    "'''\n",
    "\n",
    "class ts_corr(nn.Module):\n",
    "    def __init__(self, d=10, stride=10):\n",
    "        super(ts_corr, self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X): #X:3D\n",
    "        B, n, T = X.shape # 批量大小，特征数量，时间窗口长度\n",
    "        \n",
    "        w = (T - self.d) // self.stride + 1  # 窗口数量,例如T=10，d=3，stride=2时，w=4\n",
    "        h = n * (n - 1) // 2  # 特征对的数量 C(n, 2)\n",
    "\n",
    "        # 使用 unfold 提取滑动窗口 [形状: (B, n, w, d)]\n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        \n",
    "        #生成C(n,2)组合数\n",
    "        #例如当n=3时，rows = tensor([0,0,1]), cols = tensor([1,2,2])\n",
    "        rows, cols = torch.triu_indices(n, n, offset=1)\n",
    "\n",
    "        # 提取特征对数据得到x和y [形状: (B, h, w, d)]，分别对应batch维度，特征维度，窗口维度，时间维度\n",
    "        #x为([[:,0,:,:],[:,0,:,:],[:,1,:,:])\n",
    "        #y为([[:,1,:,:],[:,2,:,:],[:,2,:,:])\n",
    "        \n",
    "        x = unfolded_X[:, rows, :, :]\n",
    "        y = unfolded_X[:, cols, :, :]\n",
    "        \n",
    "        x_mean = torch.mean(x, dim=3, keepdim=True) #keepdim维持原本维度不变,在维度3做mean\n",
    "        y_mean = torch.mean(y, dim=3, keepdim=True)\n",
    "        \n",
    "        cov = ((x-x_mean)*(y-y_mean)).sum(dim=3) #(B, h, w)\n",
    "        corr = cov / (torch.std(x, dim=3) * torch.std(y, dim=3)+ 1e-8) #分母添加极小值防止除零错误\n",
    "\n",
    "        return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101be042",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列和Y值构成的时序数列的协方差\n",
    "'''\n",
    "\n",
    "class ts_cov(nn.Module):\n",
    "    def __init__(self, d=10, stride=10):\n",
    "        super(ts_cov, self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X):\n",
    "        B, n, T = X.shape \n",
    "        \n",
    "        w = (T - self.d) // self.stride + 1  \n",
    "        h = n * (n - 1) // 2  \n",
    "\n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        \n",
    "        rows, cols = torch.triu_indices(n, n, offset=1)\n",
    "\n",
    "        x = unfolded_X[:, rows, :, :]\n",
    "        y = unfolded_X[:, cols, :, :]\n",
    "        \n",
    "        x_mean = torch.mean(x, dim=3, keepdim=True)\n",
    "        y_mean = torch.mean(y, dim=3, keepdim=True)\n",
    "        \n",
    "        cov = ((x-x_mean)*(y-y_mean)).sum(dim=3) \n",
    "\n",
    "        return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ba47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列的标准差\n",
    "'''\n",
    "\n",
    "class ts_stddev(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_stddev,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #input:(B,n,T)，在T维度用unfold展开窗口，变为(B,n,w,d),w为窗口数量会自动计算\n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        #在每个窗口，即d维度上进行std计算\n",
    "        std = torch.std(unfolded_X, dim=3) #输出形状为(B,n,w)\n",
    "        \n",
    "        return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5c0d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列的平均值除以标准差\n",
    "'''\n",
    "\n",
    "class ts_zscore(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_zscore,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        \n",
    "        mean = torch.mean(unfolded_X, dim=3)\n",
    "        std = torch.std(unfolded_X, dim=3)\n",
    "        zscore = mean / (std + 1e-8)\n",
    "        \n",
    "        return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df1a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "研报原话为：\n",
    "(X - delay(X, d))/delay(X, d)-1, delay(X, d)为 X 在 d 天前的取值\n",
    "这里可能有误，return为“收益率“，应该是误加了-1\n",
    "为了保持代码一致性，这里计算的是(X - delay(X, d-1))/delay(X, d-1),  delay(X, d-1)为 X 在 d-1 天前的取值\n",
    "在构造卷积核的逻辑上是相似的\n",
    "'''\n",
    "\n",
    "class ts_return(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_return,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        return1 = unfolded_X[:,:,:,-1] /(unfolded_X[:,:,:,0] + 1e-8) - 1\n",
    "        \n",
    "        return return1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0496fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列的加权平均值，权数为d, d – 1, …, 1(权数之和应为1，需进行归一化处理）\n",
    "其中离现在越近的日子权数越大。 \n",
    "'''\n",
    "\n",
    "class ts_decaylinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_decaylinear,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        #如下设计的权重系数满足离现在越近的日子权重越大\n",
    "        weights = torch.arange(d, 0, -1, dtype = torch.float32) \n",
    "        weights = weights / weights.sum()\n",
    "        #注册权重，不用在前向传播函数中重复计算\n",
    "        #注册了一个形状为(d,)的一维张量，存放权重系数，以便在forward函数中使用\n",
    "        self.register_buffer('weights', weights) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        #view将一维张量广播为4D张量，并在时间维度上，将weights与unfoled_X相乘\n",
    "        decaylinear = torch.sum(unfolded_X * self.weights.view(1,1,1,-1), dim=-1)\n",
    "        \n",
    "        return decaylinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a4748",
   "metadata": {},
   "source": [
    "# v2神经网络结构设计 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5097af",
   "metadata": {},
   "source": [
    "路径(Path)：特征提取层→BN→LSTM层→BN→预测目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c5434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "路径前半部分：特征提取层→BN\n",
    "'''\n",
    "class Path1(nn.Module):\n",
    "    def __init__(self, extractor, bn_dim): #传入参数：卷积核，特征维度\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "        self.bn = nn.BatchNorm1d(bn_dim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        x = self.extractor(X) #extract\n",
    "        x = self.bn(x) #BN\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1a250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "路径后半部分：LSTM→BN→Output\n",
    "\n",
    "帮助理解LSTM：https://blog.csdn.net/mary19831/article/details/129570030\n",
    "LSTM的三个参数：\n",
    "input_size: 输入特征的维度\n",
    "hidden_size：隐藏状态的数量\n",
    "output_size：输出的维度\n",
    "num_layers：LSTM堆叠的层数\n",
    "\n",
    "'''\n",
    "class Path2(nn.Module): \n",
    "    #研报中定义，LSTM中，输出神经元数 = 30，time_step = 3\n",
    "    def __init__(self, input_size, hidden_size = 30, num_layers = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        '''\n",
    "        若batch_first = True，则lstm模型的输入维度为（batch_size,seq_len,input_size)，\n",
    "        输出维度为（batch_size,seq_len,input_size)。若默认，则batch_size与seq_len位置互换\n",
    "        研报中指定time_step = 3(seq_len = 3)，这刚好跟卷积核输出维度中的w是一样的，因此可以直接变换维度带入\n",
    "        '''\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = X.permute(0, 2, 1) #将（B，n，w）变为lstm需要的（B，w，n）\n",
    "        x, _ = self.lstm(x) #形状（B，3，hidden_size）\n",
    "        x = x[:,-1,:] # 取最后一个时间步作为输出 形状(B，hidden_size)\n",
    "        x = self.bn(x) #(B,hidden_size)\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff467db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaNet_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d=10, stride=10,n=15, T=30): #池化层窗口d=3，步长stride=3\n",
    "        super(AlphaNet_v2, self).__init__()\n",
    "        \n",
    "        self.d = d \n",
    "        self.stride = stride \n",
    "        h = n * (n - 1) // 2 #手动计算cov和corr特征提取后的特征维度大小\n",
    "        w = (T - d) // stride + 1 #手动计算特征提取层窗口数\n",
    "        \n",
    "        #特征提取层列表，共6个\n",
    "        self.extractors = nn.ModuleList([\n",
    "            ts_corr(d,stride),\n",
    "            ts_cov(d,stride),\n",
    "            ts_stddev(d,stride),\n",
    "            ts_zscore(d,stride),\n",
    "            ts_return(d,stride),\n",
    "            ts_decaylinear(d,stride),\n",
    "        ])\n",
    "        \n",
    "\n",
    "        # 初始化\n",
    "        self.Path1s = nn.ModuleList()\n",
    "        \n",
    "        # 前2个特征提取器使用h维BN\n",
    "        for i in range(2):\n",
    "            self.Path1s.append(Path1(self.extractors[i], h))\n",
    "            \n",
    "        # 后4个特征提取器使用n维BN\n",
    "        for i in range(2, 6):\n",
    "            self.Path1s.append(Path1(self.extractors[i], n))\n",
    "            \n",
    "        self.head = nn.Sequential(\n",
    "            Path2(input_size = h*2 + n*4),\n",
    "            nn.Linear(30, 1)\n",
    "        )\n",
    "\n",
    "        # 初始化线性层和输出层\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                \n",
    "                #截断正态初始化\n",
    "                fan_in = m.weight.size(1)\n",
    "                std = math.sqrt(1.0 / fan_in)  # Xavier方差标准\n",
    "                nn.init.trunc_normal_(m.weight, std=std, a=-2*std, b=2*std)\n",
    "                nn.init.normal_(m.bias, std=1e-6)\n",
    "                \n",
    "                #Kaiming初始化\n",
    "                #nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                \n",
    "                #Xavier初始化\n",
    "                #nn.init.xavier_uniform_(m.weight)\n",
    "                #nn.init.normal_(m.bias, std=1e-6)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        features = [path(X) for path in self.Path1s] \n",
    "        features = torch.cat(features, dim=1)\n",
    "        \n",
    "        return self.head(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab419bff",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e9ec6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (930008, 15, 30)\n",
      "Shape of Y:  (930008,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('npy_v2/X_fe.npy')\n",
    "Y = np.load('npy_v2/Y_fe.npy')\n",
    "dates = np.load('npy_v2/Y_dates.npy')\n",
    "\n",
    "print('Shape of X: ', X.shape)\n",
    "print('Shape of Y: ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74e91eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对X进行窗口标准化\n",
    "'''\n",
    "class myDataset(Dataset):\n",
    "    '''\n",
    "    自定义数据集，将原始数据从 numpy arrays 转换成 float 格式的 tensors\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, y, scaler = None, is_train = True):\n",
    "        super(myDataset, self).__init__()\n",
    "        self.y = y.reshape(-1, 1)\n",
    "        \n",
    "        self.origin_shape = X.shape\n",
    "        \n",
    "        # (B, n, T) → (B*T, n)\n",
    "        X_2d = X.reshape(-1, self.origin_shape[1]) \n",
    "        \n",
    "        #训练模式，同时完成拟合（计算均值和标准差）和转换（应用标准化）\n",
    "        if is_train: \n",
    "            self.scaler = StandardScaler()\n",
    "            X_trans = self.scaler.fit_transform(X_2d)\n",
    "            #X_trans = np.clip(X_trans, -5, 5)  # 限制标准化后的值在±5个标准差内\n",
    "        \n",
    "        #验证/测试模式，仅进行转换（应用标准化），不重新计算均值和标准差\n",
    "        #预先计算好的均值和标准差存储在标准化器（StandardScaler）的内部属性中\n",
    "        \n",
    "        else: \n",
    "            self.scaler = scaler\n",
    "            X_trans = self.scaler.transform(X_2d)\n",
    "            \n",
    "        self.X = X_trans.reshape(self.origin_shape)\n",
    "        self.X = torch.as_tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.as_tensor(self.y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def get_scaler(self):\n",
    "        return self.scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c438a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphanet_v2 = AlphaNet_v2(d=10, stride=10, n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865323c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8492],\n",
       "        [ 1.1502],\n",
       "        [-0.4877],\n",
       "        [-0.3041],\n",
       "        [-1.2076]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphanet_v2(torch.tensor(X[:5]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85329938",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dates = np.array([datetime.strptime(str(date), '%Y-%m-%d').date() for date in dates])\n",
    "unique_dates = sorted(np.unique(target_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b28cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到不同的轮次,确保每个轮次为1626天\n",
    "\n",
    "start_dates = []\n",
    "starts, valid_starts, test_starts, ends,  = [], [], [], []\n",
    "\n",
    "i, start, end = 0, 0, 0\n",
    "\n",
    "k = int(1500*0.8) #按4：1划分训练集和测试集\n",
    "\n",
    "while i + 1500 + 126 <= len(unique_dates):\n",
    "    start_dates.append(i)\n",
    "    \n",
    "    start = sum(target_dates < unique_dates[i])\n",
    "    starts.append(start)\n",
    "    \n",
    "    valid_start = sum(target_dates < unique_dates[i+k]) #训练集终点\n",
    "    valid_starts.append(valid_start)\n",
    "    \n",
    "    test_start = sum(target_dates < unique_dates[i+1500]) #验证集重点（1500天）\n",
    "    test_starts.append(test_start)\n",
    "    \n",
    "    end = sum(target_dates < unique_dates[i+1500+126]) #测试集终点（再126天）\n",
    "    ends.append(end)\n",
    "    \n",
    "    i += 126"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27235eed",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a9fc3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.1872, Validation Loss: 0.0591\n",
      "Saved model with validation loss of 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.0557, Validation Loss: 0.0307\n",
      "Saved model with validation loss of 0.0307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.0326, Validation Loss: 0.0195\n",
      "Saved model with validation loss of 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:16<00:00,  6.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.0235, Validation Loss: 0.0139\n",
      "Saved model with validation loss of 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:16<00:00,  6.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.0180, Validation Loss: 0.0113\n",
      "Saved model with validation loss of 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 0.0152, Validation Loss: 0.0096\n",
      "Saved model with validation loss of 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 0.0127, Validation Loss: 0.0077\n",
      "Saved model with validation loss of 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 0.0112, Validation Loss: 0.0071\n",
      "Saved model with validation loss of 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: 0.0099, Validation Loss: 0.0062\n",
      "Saved model with validation loss of 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 0.0086, Validation Loss: 0.0053\n",
      "Saved model with validation loss of 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Training Loss: 0.0079, Validation Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss: 0.0073, Validation Loss: 0.0046\n",
      "Saved model with validation loss of 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Training Loss: 0.0068, Validation Loss: 0.0042\n",
      "Saved model with validation loss of 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Training Loss: 0.0063, Validation Loss: 0.0039\n",
      "Saved model with validation loss of 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Training Loss: 0.0060, Validation Loss: 0.0035\n",
      "Saved model with validation loss of 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Training Loss: 0.0055, Validation Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Training Loss: 0.0053, Validation Loss: 0.0031\n",
      "Saved model with validation loss of 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Training Loss: 0.0049, Validation Loss: 0.0028\n",
      "Saved model with validation loss of 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Training Loss: 0.0046, Validation Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss: 0.0043, Validation Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Training Loss: 0.0042, Validation Loss: 0.0026\n",
      "Saved model with validation loss of 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Training Loss: 0.0040, Validation Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Training Loss: 0.0038, Validation Loss: 0.0024\n",
      "Saved model with validation loss of 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Training Loss: 0.0036, Validation Loss: 0.0023\n",
      "Saved model with validation loss of 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Training Loss: 0.0034, Validation Loss: 0.0021\n",
      "Saved model with validation loss of 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Training Loss: 0.0033, Validation Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Training Loss: 0.0033, Validation Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Training Loss: 0.0031, Validation Loss: 0.0019\n",
      "Saved model with validation loss of 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Training Loss: 0.0030, Validation Loss: 0.0018\n",
      "Saved model with validation loss of 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Training Loss: 0.0030, Validation Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Training Loss: 0.0029, Validation Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Training Loss: 0.0028, Validation Loss: 0.0017\n",
      "Saved model with validation loss of 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Training Loss: 0.0027, Validation Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Training Loss: 0.0026, Validation Loss: 0.0016\n",
      "Saved model with validation loss of 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Training Loss: 0.0026, Validation Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Training Loss: 0.0025, Validation Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Training Loss: 0.0024, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Training Loss: 0.0024, Validation Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Training Loss: 0.0023, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Training Loss: 0.0022, Validation Loss: 0.0014\n",
      "Saved model with validation loss of 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:18<00:00,  5.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Training Loss: 0.0022, Validation Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Training Loss: 0.0022, Validation Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:19<00:00,  5.35it/s]\n",
      " 59%|████████████████████████████████████████████████▋                                 | 19/32 [00:03<00:02,  5.91it/s]"
     ]
    }
   ],
   "source": [
    "#### 设置随机种子，保证训练结果一致\n",
    "torch.manual_seed(42)\n",
    "#torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# 设置训练参数：学习率、训练迭代次数、批量大小\n",
    "lr = 0.0001\n",
    "n_epoch = 100\n",
    "batch_size = 2000\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model_name = 'alphanet'\n",
    "\n",
    "# 初始化一个字典，用来储存模型训练期间的表现\n",
    "results = {}\n",
    "results['round'] = []\n",
    "results['train'] = []\n",
    "results['valid'] = []\n",
    "results['test'] = []\n",
    "\n",
    "# 维护 cnt 变量，记录当前是第几个训练轮次\n",
    "cnt = 0\n",
    "\n",
    "# 滚动窗口\n",
    "for start, valid_start, test_start, end in zip(starts, valid_starts, test_starts, ends):\n",
    "    \n",
    "    # 初始化损失函数和优化器\n",
    "    net = AlphaNet_v2(d=10, stride=10, n=15)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    # 划分集\n",
    "    train_set = myDataset(X[start:valid_start], Y[start:valid_start], is_train=True)\n",
    "    train_scaler = train_set.get_scaler()\n",
    "    \n",
    "    valid_set = myDataset(X[valid_start:test_start], Y[valid_start:test_start], scaler = train_scaler, is_train=False)\n",
    "    \n",
    "    test_set = myDataset(X[test_start:end], Y[test_start:end], scaler = train_scaler, is_train=False)\n",
    "\n",
    "    # 创建loader\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 当前训练轮次的模型储存地址\n",
    "    model_path = 'Models_v2/' + model_name + '_' + str(cnt) + '.pt'\n",
    "    \n",
    "    count = 0\n",
    "    train_loss_lst, valid_loss_lst = [], []\n",
    "    best_valid_loss = float('inf')\n",
    "    patience = 10\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        # 训练\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        total_samples = 0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = net(x)\n",
    "            loss = criterion(preds, y)\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            total_samples += x.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= total_samples\n",
    "        \n",
    "        # 验证\n",
    "        net.eval()\n",
    "        valid_loss = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(valid_loader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds = net(x)\n",
    "                loss = criterion(preds, y)\n",
    "                valid_loss += loss.item() * x.size(0)\n",
    "                total_samples += x.size(0)\n",
    "        valid_loss /= total_samples\n",
    "\n",
    "        # 监测训练效果\n",
    "        print(\"Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}\".format(epoch+1, train_loss, valid_loss))\n",
    "        \n",
    "        # 记录训练效果\n",
    "        train_loss_lst.append(train_loss)\n",
    "        valid_loss_lst.append(valid_loss)\n",
    "        \n",
    "        # 更新本地模型\n",
    "        if valid_loss < best_valid_loss - 1e-4:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(\"Saved model with validation loss of {:.4f}\".format(best_valid_loss)) \n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "            \n",
    "        # 早停：若累计有patience次迭代，模型都没有进步，停止本轮训练\n",
    "        if count >= patience:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    # 记录当前训练轮次的指标变动，并更新本地储存结果\n",
    "    results['round'].append(str(cnt))          \n",
    "    results['train'].append(train_loss_lst)   \n",
    "    results['valid'].append(valid_loss_lst)   \n",
    "    with open(f'Models_v2/train_results_{cnt}.pickle', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    # 下一轮\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ecf3c6",
   "metadata": {},
   "source": [
    "# 查看轮次对应的时间区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2578723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_range(round_idx):\n",
    "    # 获取指定轮次的时间区间\n",
    "    train_start_date = unique_dates[starts[round_idx]]\n",
    "    valid_start_date = unique_dates[valid_starts[round_idx]]\n",
    "    test_start_date = unique_dates[test_starts[round_idx]]\n",
    "    test_end_date = unique_dates[ends[round_idx]]\n",
    "    \n",
    "    return {\n",
    "        \"train\": (train_start_date, valid_start_date - timedelta(days=1)),\n",
    "        \"valid\": (valid_start_date, test_start_date - timedelta(days=1)),\n",
    "        \"test\": (test_start_date, test_end_date)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = get_time_range(2)\n",
    "print(f\"\"\"\n",
    "训练集: {time_range['train'][0]} 至 {time_range['train'][1]}\n",
    "验证集: {time_range['valid'][0]} 至 {time_range['valid'][1]}\n",
    "测试集: {time_range['test'][0]} 至 {time_range['test'][1]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a13e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
